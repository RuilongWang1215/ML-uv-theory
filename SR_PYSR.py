# This script is the symbolic regression framework for modelling the correction term of uv-theory
import numpy as np
import pandas as pd
import time
from pysr import PySRRegressor
import sympy as sp
# import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import os
import psutil
import numpy as np
from restriction import *

# This function is used to organize the files generated by the symbolic regression
'''It will move the generated files to the 'result' folder and rename them
The naming convention is 'uv_trial_{substance}_{count}.csv'
The count is the number of files with the same substance name'''

class PYSR_wrapper():
    def __init__(self, substance, X, y, test_ratio=0.2, iteration=100, MAXSIZE=35,
                 WEIGHTED=False):
        self.base_path = os.path.dirname(__file__)
        self.substance = substance
        self.model = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.test_ratio = test_ratio
        self.iteration = iteration
        self.maxsize = MAXSIZE
        self.X = X
        self.y = y
        self.weighted = WEIGHTED
        if self.weighted:
            self.NAME = 'pySR_w_' + substance+ '_iter'+ str(iteration)
        self.NAME = 'pySR_' + substance+ '_iter'+ str(iteration)+ time.strftime("_%H%M")
        
    def organize_files(self):
        if not os.path.exists(self.base_path+'/result_pysr'):
            os.makedirs(self.base_path+'/result_pysr')
        file_names = os.listdir()
        file_in_result = os.listdir(self.base_path+'/result_pysr')
        r = Restriction(self.model)
        fulfillment = None
        restrictions_result = run_restriction_check(r)
        if all(all(res) if isinstance(res, (list, tuple)) else res for res in restrictions_result.values()):
            fulfillment = True
        else:
            fulfillment = False
        print(f"Restrictions for {self.substance} are fulfilled: {fulfillment}")
        if fulfillment:
            for file_name in file_names:
                if file_name.startswith('hall_of_fame'):
                    if file_name.endswith('.csv'):
                        os.replace(file_name, self.base_path+'/result_pysr/' + self.NAME + '.csv')
                    if file_name.endswith('.pkl'):
                        os.replace(file_name, self.base_path+'/result_pysr/' + self.NAME +'.pkl')
                    if file_name.endswith('.bkup'):
                        os.remove(file_name)
        else:
            # delete the files that start with 'hall_of_fame'
            for file_name in file_names:
                if file_name.startswith('hall_of_fame'):
                    os.remove(file_name)
        return fulfillment
                    
    def X_transform(self, X):
        X_transformed = X.copy()  
        X_transformed.loc[:,'density'] = X_transformed.loc[:,'density'] / (1 + X_transformed.loc[:,'density']**2)
        return X_transformed

    def data_split(self):
        self.X_train, self.X_test, self.y_train, self.y_test = \
            train_test_split(self.X, self.y, test_size=self.test_ratio)
        
    def plot_regression(self):
        y_pred = self.model.predict(self.X_test)
        r2 = r2_score(self.y_test, y_pred)
        fig = plt.figure()
        plt.plot(self.y_test, y_pred, 'o', color='skyblue')
        plt.plot(self.y_test, self.y_test, 'slategrey')
        plt.text(0.7, 0.2, f'R2: {r2:.2f}', transform=fig.transFigure)
        plt.xlabel('True')
        plt.ylabel('Predicted')
        #plt.title(f"True vs Predicted {self.substance} Correction Term")
        if not os.path.exists(self.base_path+'/result_pysr/pictures'):
            os.makedirs(self.base_path+'/result_pysr/pictures')
        plt.savefig(self.base_path+f"/result_pysr/pictures/{self.NAME}_{round(r2,4)}.png", dpi=300, bbox_inches='tight')
        
    def weighted_loss(self, prediction, target):
        unique_nu, counts = np.unique(self.X_train['nu'], return_counts=True)
        weights_dict = {nu: 1 / count for nu, count in zip(unique_nu, counts)}
        weights = np.array([weights_dict[nu] for nu in self.X_train['nu']])
        loss = 0
        for nu in unique_nu:
            # Identify indices where nu matches
            indices = self.X_train['nu'] == nu
            # Compute weighted loss for this category
            weight = weights[nu]
            loss += weight * np.sum((prediction[indices] - target[indices])**2)
        return loss
    
    def run_SR(self):
        self.data_split()
        if self.weighted:
            unique_nu, counts = np.unique(self.X_train['nu'], return_counts=True)
            weights_dict = {nu: 1 / count for nu, count in zip(unique_nu, counts)}
            WEIGHT = np.array([weights_dict[nu] for nu in self.X_train['nu']])
            ELEMENTWISE_LOSS = "loss(prediction, target, w) = w*(prediction - target)^2"
        else:
            WEIGHT = None
            ELEMENTWISE_LOSS = "loss(prediction, target) = (prediction - target)^2"
            
        #density = self.X_train['density']
        #weights = density/(10**(-16)+density**1.005)
        model = PySRRegressor(
            niterations=self.iteration,
            procs=psutil.cpu_count(),  # use all available cores
            populations=psutil.cpu_count()*3,
            maxsize = self.maxsize,
            binary_operators=["+", "*", "-", "/"],
            unary_operators=[
                "cos",
                "sin",
                "exp",
                "tan",
                "sqrt",
                "log",
                "square",
                "cube",
                "sinh(x) = (exp(x) - exp(-x))/2",
                "cosh(x) = (exp(x) + exp(-x))/2",
            ],
            extra_sympy_mappings={#"inv": lambda x: 1 / x,
                                "sinh": lambda x: (sp.exp(x) - sp.exp(-x)) / 2,
                                "cosh": lambda x: (sp.exp(x) + sp.exp(-x)) / 2,
                                },
            complexity_of_operators={"sin": 3, "cos": 3, "tan":3
                                     ,"sinh":3,"cosh":3},
            elementwise_loss=ELEMENTWISE_LOSS,
            ncycles_per_iteration = self.iteration,
            timeout_in_seconds = 60*60*8,
            model_selection='best',
            progress= True,
            batching = True,
            bumper = True,)  
        
        model.fit(self.X_train, self.y_train, weights=WEIGHT)
        #self.plot_regression()
        fulfillment= self.organize_files()
        print(f"Model for {self.substance} has been saved")
        return fulfillment, model




